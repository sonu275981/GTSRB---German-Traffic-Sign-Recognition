{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload kaggle json file\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running ls command for checking downloded files\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout,Activation\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "cur_path = r'C:\\Users\\sonuc\\Desktop\\Data_Science\\Traffic_sign_pridection\\gtsrb-german-traffic-sign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 43\n",
    " \n",
    "\n",
    "#Retrieving the images and their labels \n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,'train',str(i))\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '\\\\'+ a)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "    \n",
    "            #data.append(image)\n",
    "            #labels.append(i)\n",
    "            data.append([image,i]) #appending all value together \n",
    "        except:\n",
    "            print(\"Error loading image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39209\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for features,label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Converting lists into numpy arrays\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_val = X_val/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array(x).reshape(-1, 30, 30, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train images is: (31367, 30, 30, 3)\n",
      "Shape of labels is: (31367,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train images is:\", X_train.shape)\n",
    "print(\"Shape of labels is:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(30, 30, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(43))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 2.4228 - accuracy: 0.3027 - val_loss: 1.2111 - val_accuracy: 0.5916\n",
      "Epoch 2/15\n",
      "981/981 [==============================] - 27s 28ms/step - loss: 1.1788 - accuracy: 0.6083 - val_loss: 0.5073 - val_accuracy: 0.8460\n",
      "Epoch 3/15\n",
      "981/981 [==============================] - 27s 28ms/step - loss: 0.6783 - accuracy: 0.7732 - val_loss: 0.2597 - val_accuracy: 0.9227\n",
      "Epoch 4/15\n",
      "981/981 [==============================] - 20s 20ms/step - loss: 0.4359 - accuracy: 0.8542 - val_loss: 0.1192 - val_accuracy: 0.9652\n",
      "Epoch 5/15\n",
      "981/981 [==============================] - 12s 12ms/step - loss: 0.3253 - accuracy: 0.8952 - val_loss: 0.0940 - val_accuracy: 0.9776\n",
      "Epoch 6/15\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 0.2449 - accuracy: 0.9202 - val_loss: 0.0588 - val_accuracy: 0.9844\n",
      "Epoch 7/15\n",
      "981/981 [==============================] - 12s 12ms/step - loss: 0.2057 - accuracy: 0.9326 - val_loss: 0.0531 - val_accuracy: 0.9856\n",
      "Epoch 8/15\n",
      "981/981 [==============================] - 12s 12ms/step - loss: 0.1791 - accuracy: 0.9446 - val_loss: 0.0493 - val_accuracy: 0.9861\n",
      "Epoch 9/15\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 0.1522 - accuracy: 0.9516 - val_loss: 0.0470 - val_accuracy: 0.9858\n",
      "Epoch 10/15\n",
      "981/981 [==============================] - 12s 12ms/step - loss: 0.1390 - accuracy: 0.9556 - val_loss: 0.0428 - val_accuracy: 0.9875\n",
      "Epoch 11/15\n",
      "981/981 [==============================] - 12s 12ms/step - loss: 0.1233 - accuracy: 0.9610 - val_loss: 0.0307 - val_accuracy: 0.9915\n",
      "Epoch 12/15\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 0.1127 - accuracy: 0.9645 - val_loss: 0.0251 - val_accuracy: 0.9930\n",
      "Epoch 13/15\n",
      "981/981 [==============================] - 12s 12ms/step - loss: 0.0978 - accuracy: 0.9698 - val_loss: 0.0314 - val_accuracy: 0.9904\n",
      "Epoch 14/15\n",
      "981/981 [==============================] - 12s 12ms/step - loss: 0.0982 - accuracy: 0.9696 - val_loss: 0.0273 - val_accuracy: 0.9918\n",
      "Epoch 15/15\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 0.0853 - accuracy: 0.9736 - val_loss: 0.0324 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=15, validation_data=(X_val, y_val))\n",
    "\n",
    "model.save('my_model2.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Test/00000.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0b03af44178a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2911\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2912\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Test/00000.png'"
     ]
    }
   ],
   "source": [
    "#testing accuracy on test dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test = pd.read_csv('gtsrb-german-traffic-sign/Test.csv')\n",
    "\n",
    "labels = y_test[\"ClassId\"].values\n",
    "imgs = y_test[\"Path\"].values\n",
    "\n",
    "data=[]\n",
    "\n",
    "for img in imgs:\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((30,30))\n",
    "    data.append(np.array(image))\n",
    "\n",
    "X_test=np.array(data)\n",
    "\n",
    "pred = model.predict_classes(X_test)  \n",
    "\n",
    "#Accuracy with the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are testing our model on our saved model also we can test on our 15 epoch data result we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with random image\n",
    "# upload your saved model file\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with random image\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras_preprocessing import image\n",
    "from IPython.display import Image,display\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  path = '/content/files/'+ fn #save the image to content folder\n",
    "  img = image.load_img(path, target_size = (30,30)) #load the image\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  images = np.vstack([x])\n",
    "\n",
    "  value = classes = np.argmax(model.predict(images,batch_size=32),axis=-1) #predict the label for the image\n",
    "\n",
    "  if classes[0]==0:\n",
    "    print(fn + ', Speed limit (20km/h)'),display(Image(fn)) #print the content\n",
    "\n",
    "  elif classes[0]==1:\n",
    "      print(fn + ', Speed limit (30km/h)'),display(Image(fn)) #print the content\n",
    "\n",
    "  elif classes[0]==2:\n",
    "      print(fn + ', Speed limit (50km/h)'),display(Image(fn)) #print the content\n",
    "\n",
    "  elif classes[0]==3:\n",
    "      print(fn + ', Speed limit (60km/h)'),display(Image(fn)) #print the content\n",
    "\n",
    "  elif classes[0]==4:\n",
    "      print(fn + ', Speed limit (70km/h)'),display(Image(fn)) #print the content\n",
    "\n",
    "  elif classes[0]==5:\n",
    "      print(fn + ', Speed limit (80km/h)'),display(Image(fn)) #print the content\n",
    "\n",
    "  elif classes[0]==6:\n",
    "      print(fn + ', End of speed limit (80km/h)'),display(Image(fn)) #print the content\n",
    "\n",
    "  elif classes[0]==7:\n",
    "      print(fn + ', Speed limit (100km/h)'),display(Image(fn)) #print the content\n",
    "\n",
    "  elif classes[0]==8:\n",
    "      print(fn + ', Speed limit (120km/h)'),display(Image(fn)) #print the content\n",
    "\n",
    "  elif classes[0]==9:\n",
    "      print(fn + ', No passing'),display(Image(fn)) #print the content\n",
    "        \n",
    "  elif classes[0]==10:\n",
    "      print(fn + ', No passing veh over 3.5 tons'),display(Image(fn)) #print the content \n",
    "        \n",
    "  elif classes[0]==11:\n",
    "      print(fn + ', Right-of-way at intersection'),display(Image(fn)) #print the content\n",
    "        \n",
    "  elif classes[0]==12:\n",
    "      print(fn + ', Priority road'),display(Image(fn)) #print the content\n",
    "        \n",
    "  elif classes[0]==13:\n",
    "      print(fn + ', Yield'),display(Image(fn)) #print the content       \n",
    "        \n",
    "  elif classes[0]==14:\n",
    "      print(fn + ', Stop'),display(Image(fn)) #print the content       \n",
    "        \n",
    "  elif classes[0]==15:\n",
    "      print(fn + ', No vehicles'),display(Image(fn)) #print the content\n",
    "                \n",
    "  elif classes[0]==16:\n",
    "      print(fn + ', Veh > 3.5 tons prohibited'),display(Image(fn)) #print the content       \n",
    "        \n",
    "  elif classes[0]==17:\n",
    "      print(fn + ', No entry'),display(Image(fn)) #print the content        \n",
    "                       \n",
    "  elif classes[0]==18:\n",
    "      print(fn + ', General caution'),display(Image(fn)) #print the content       \n",
    "                \n",
    "  elif classes[0]==19:\n",
    "      print(fn + ', Dangerous curve left'),display(Image(fn)) #print the content        \n",
    "        \n",
    "  elif classes[0]==20:\n",
    "      print(fn + ', Dangerous curve right'),display(Image(fn)) #print the content        \n",
    "        \n",
    "  elif classes[0]==21:\n",
    "      print(fn + ', Double curve'),display(Image(fn)) #print the content       \n",
    "        \n",
    "  elif classes[0]==22:\n",
    "      print(fn + ', Bumpy road'),display(Image(fn)) #print the content        \n",
    "                \n",
    "  elif classes[0]==23:\n",
    "      print(fn + ', Slippery road'),display(Image(fn)) #print the content        \n",
    "        \n",
    "  elif classes[0]==24:\n",
    "      print(fn + ', Road narrows on the right'),display(Image(fn)) #print the content               \n",
    "        \n",
    "  elif classes[0]==25:\n",
    "      print(fn + ', Road work'),display(Image(fn)) #print the content        \n",
    "        \n",
    "  elif classes[0]==26:\n",
    "      print(fn + ', Traffic signals'),display(Image(fn)) #print the content\n",
    "        \n",
    "  elif classes[0]==27:\n",
    "      print(fn + ', Pedestrians'),display(Image(fn)) #print the content       \n",
    "                \n",
    "  elif classes[0]==28:\n",
    "      print(fn + ', Children crossing'),display(Image(fn)) #print the content\n",
    "        \n",
    "  elif classes[0]==29:\n",
    "      print(fn + ', Bicycles crossing'),display(Image(fn)) #print the content\n",
    "               \n",
    "  elif classes[0]==30:\n",
    "      print(fn + ', Beware of ice/snow'),display(Image(fn)) #print the content        \n",
    "        \n",
    "  elif classes[0]==31:\n",
    "      print(fn + ', Wild animals crossing'),display(Image(fn)) #print the content        \n",
    "               \n",
    "  elif classes[0]==32:\n",
    "      print(fn + ', End speed + passing limits'),display(Image(fn)) #print the content        \n",
    "        \n",
    "  elif classes[0]==33:\n",
    "      print(fn + ', Turn right ahead'),display(Image(fn)) #print the content\n",
    "        \n",
    "  elif classes[0]==34:\n",
    "      print(fn + ', Turn left ahead'),display(Image(fn)) #print the content        \n",
    "        \n",
    "  elif classes[0]==35:\n",
    "      print(fn + ', Ahead only'),display(Image(fn)) #print the content        \n",
    "        \n",
    "  elif classes[0]==36:\n",
    "      print(fn + ', Go straight or right'),display(Image(fn)) #print the content\n",
    "        \n",
    "  elif classes[0]==37:\n",
    "      print(fn + ', Go straight or left'),display(Image(fn)) #print the content        \n",
    "        \n",
    "  elif classes[0]==38:\n",
    "      print(fn + ', Keep right'),display(Image(fn)) #print the content\n",
    "        \n",
    "  elif classes[0]==39:\n",
    "      print(fn + ', Keep left'),display(Image(fn)) #print the content       \n",
    "        \n",
    "  elif classes[0]==40:\n",
    "      print(fn + ', Roundabout mandatory'),display(Image(fn)) #print the content\n",
    "\n",
    "  elif classes[0]==41:\n",
    "      print(fn + ', End of no passing'),display(Image(fn)) #print the content        \n",
    "        \n",
    "  else:\n",
    "      print(fn + ', End no passing veh > 3.5 tons'),display(Image(fn)) #print the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
